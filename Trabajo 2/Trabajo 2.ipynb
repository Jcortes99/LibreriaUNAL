{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c33f0c5",
   "metadata": {},
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e5d0ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scrapy in c:\\programdata\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (1.5.0)\n",
      "Requirement already satisfied: protego>=0.1.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (0.1.16)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (2.0.5)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (65.6.3)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (22.0)\n",
      "Requirement already satisfied: parsel>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (1.6.0)\n",
      "Requirement already satisfied: zope.interface>=5.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (5.4.0)\n",
      "Requirement already satisfied: service-identity>=18.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (18.1.0)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (0.3.0)\n",
      "Requirement already satisfied: Twisted>=18.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (22.2.0)\n",
      "Requirement already satisfied: lxml>=4.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (4.9.1)\n",
      "Requirement already satisfied: pyOpenSSL>=21.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (23.0.0)\n",
      "Requirement already satisfied: cryptography>=3.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (39.0.1)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (1.21.0)\n",
      "Requirement already satisfied: tldextract in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (3.2.0)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (1.0.4)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapy) (1.1.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from cryptography>=3.4.6->scrapy) (1.15.1)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from itemloaders>=1.0.1->scrapy) (0.10.0)\n",
      "Requirement already satisfied: six>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from parsel>=1.5.0->scrapy) (1.16.0)\n",
      "Requirement already satisfied: attrs>=16.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (22.1.0)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\programdata\\anaconda3\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (0.2.8)\n",
      "Requirement already satisfied: pyasn1 in c:\\programdata\\anaconda3\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (0.4.8)\n",
      "Requirement already satisfied: constantly>=15.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (15.1.0)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (21.0.0)\n",
      "Requirement already satisfied: Automat>=0.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (20.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (4.4.0)\n",
      "Requirement already satisfied: twisted-iocpsupport<2,>=1.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (1.0.2)\n",
      "Requirement already satisfied: incremental>=21.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (21.3.0)\n",
      "Requirement already satisfied: requests-file>=1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from tldextract->scrapy) (1.5.1)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from tldextract->scrapy) (3.4)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tldextract->scrapy) (3.9.0)\n",
      "Requirement already satisfied: requests>=2.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tldextract->scrapy) (2.28.1)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=3.4.6->scrapy) (2.21)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (1.26.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.7.2-cp310-cp310-win_amd64.whl (12.1 MB)\n",
      "     ---------------------------------------- 12.1/12.1 MB 9.8 MB/s eta 0:00:00\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.9-cp310-cp310-win_amd64.whl (122 kB)\n",
      "     ---------------------------------------- 122.2/122.2 kB ? eta 0:00:00\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4\n",
      "  Downloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
      "     ------------------------------------- 395.8/395.8 kB 24.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.8-cp310-cp310-win_amd64.whl (39 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "     ---------------------------------------- 181.6/181.6 kB ? eta 0:00:00\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "     ---------------------------------------- 45.9/45.9 kB ? eta 0:00:00\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.8-cp310-cp310-win_amd64.whl (481 kB)\n",
      "     ------------------------------------- 481.9/481.9 kB 29.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (65.6.3)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.23.5)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Collecting thinc<8.3.0,>=8.1.8\n",
      "  Downloading thinc-8.2.1-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 18.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (22.0)\n",
      "Collecting weasel<0.4.0,>=0.1.0\n",
      "  Downloading weasel-0.3.3-py3-none-any.whl (49 kB)\n",
      "     ---------------------------------------- 49.8/49.8 kB ? eta 0:00:00\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.10-cp310-cp310-win_amd64.whl (25 kB)\n",
      "Collecting pydantic-core==2.10.1\n",
      "  Downloading pydantic_core-2.10.1-cp310-none-win_amd64.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 43.0 MB/s eta 0:00:00\n",
      "Collecting typing-extensions>=4.6.1\n",
      "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.1.3-py3-none-any.whl (34 kB)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.11-cp310-cp310-win_amd64.whl (6.6 MB)\n",
      "     ---------------------------------------- 6.6/6.6 MB 35.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "     ---------------------------------------- 45.0/45.0 kB ? eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Installing collected packages: cymem, wasabi, typing-extensions, spacy-loggers, spacy-legacy, murmurhash, langcodes, catalogue, blis, annotated-types, typer, srsly, pydantic-core, preshed, cloudpathlib, pydantic, confection, weasel, thinc, spacy\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "Successfully installed annotated-types-0.6.0 blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 confection-0.1.3 cymem-2.0.8 langcodes-3.3.0 murmurhash-1.0.10 preshed-3.0.9 pydantic-2.4.2 pydantic-core-2.10.1 spacy-3.7.2 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.1 typer-0.9.0 typing-extensions-4.8.0 wasabi-1.1.2 weasel-0.3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting es-core-news-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
      "     --------------------------------------- 12.9/12.9 MB 13.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from es-core-news-sm==3.7.0) (3.7.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (22.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.28.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.23.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.3.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.64.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (5.2.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (65.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.8.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.10.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.1.1)\n",
      "Installing collected packages: es-core-news-sm\n",
      "Successfully installed es-core-news-sm-3.7.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n",
      "Collecting es-core-news-md==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_md-3.7.0/es_core_news_md-3.7.0-py3-none-any.whl (42.3 MB)\n",
      "     --------------------------------------- 42.3/42.3 MB 28.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from es-core-news-md==3.7.0) (3.7.2)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.3.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (5.2.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (65.6.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (4.64.1)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.28.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (22.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.23.5)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (4.8.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.1.1)\n",
      "Installing collected packages: es-core-news-md\n",
      "Successfully installed es-core-news-md-3.7.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_md')\n"
     ]
    }
   ],
   "source": [
    "#Importar librerias de Scrappy\n",
    "%pip install scrapy\n",
    "%pip install spacy\n",
    "%pip install nltk\n",
    "#Importar librerias de spacy para español\n",
    "!python -m spacy download es_core_news_sm\n",
    "!python -m spacy download es_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "678f64f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dgbla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dgbla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Asegurarse que se tienen todas las librerias incluidas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import es_core_news_sm\n",
    "import es_core_news_md\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3c85f3",
   "metadata": {},
   "source": [
    "# Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d238981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add(\"\\\"\")\n",
    "stop_words.add(\"'\")\n",
    "stop_words.add(\"’\")\n",
    "stop_words.add(\"”\")\n",
    "stop_words.add(\"!\")\n",
    "stop_words.add(\"“\")\n",
    "stop_words.add(\"?\")\n",
    "\n",
    "def preProcess(path):\n",
    "    # LEE \n",
    "    with open(path, 'r') as f:\n",
    "        file = f.readlines()\n",
    "    \n",
    "    title = file[0][:-1]\n",
    "    synopsis = \" \".join(file[1::])\n",
    "\n",
    "    #Minusculas\n",
    "    lower_text = synopsis.lower()\n",
    "\n",
    "    #Eliminar signos de puntuación\n",
    "    nlp = es_core_news_sm.load()\n",
    "    doc = nlp(lower_text)\n",
    "    tokens=[]\n",
    "    # revision de signos de puntuacion y en caso de que no sea se agrega\n",
    "    for token in doc:\n",
    "        if token.is_punct==False:\n",
    "            tokens.append(token.text)\n",
    "\n",
    "    clean_text = \" \".join(tokens)\n",
    "\n",
    "    #Stopwords\n",
    "    new_tokens = word_tokenize(clean_text)\n",
    "    clean_tokens = [w for w in new_tokens if not w in stop_words]\n",
    "    final_text = \" \".join(clean_tokens)\n",
    "    \n",
    "    # Guarda\n",
    "    new_path = path[:53] + '-clean' + path[53:]\n",
    "    with open(new_path, 'w') as f:\n",
    "        f.write(f'{title}\\n{final_text}')\n",
    "    \n",
    "    # returns\n",
    "    return (int(path[54:-4]), clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ab126ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "def vect(df, id, cleantokens):\n",
    "    current = list(df.columns)\n",
    "    c = set(clean_tokens)\n",
    "    zvect = [0] * df.shape[0]\n",
    "    for p in c:\n",
    "        if p not in current:\n",
    "            df[p] = zvect\n",
    "            current.append(p)\n",
    "    d = dict()\n",
    "    for it in current:\n",
    "        if it in c:\n",
    "            sum = clean_tokens.count(it)\n",
    "            d[it] = sum/len(clean_tokens)\n",
    "        else:\n",
    "            d[it] = 0\n",
    "    new_record = pd.DataFrame([d])\n",
    "    df = pd.concat([df, new_record], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc19e30",
   "metadata": {},
   "source": [
    "# Web Scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f3f249",
   "metadata": {},
   "source": [
    "## Crear el proyecto de Scrappy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936782aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy startproject GoodReadsScraper\n",
    "%cd GoodReadsScraper/GoodReadsScraper/spiders/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e222ef3",
   "metadata": {},
   "source": [
    "## Crear un nuevo Spyder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2db7962f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Documents\\University\\Recuperacion Web\\LibreriaUNAL\\Trabajo 2\\GoodReadsScraper\\GoodReadsScraper\\spiders\\GoodReadsSpider.py already exists\n"
     ]
    }
   ],
   "source": [
    "!scrapy genspider GoodReadsSpider https://www.goodreads.com/shelf/show/fiction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28553641",
   "metadata": {},
   "source": [
    "## Ejecutar el Spyder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1cacb4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-29 18:14:38 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: GoodReadsScraper)\n",
      "2023-10-29 18:14:38 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.2.0, Python 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.0.0 (OpenSSL 1.1.1t  7 Feb 2023), cryptography 39.0.1, Platform Windows-10-10.0.22621-SP0\n",
      "2023-10-29 18:14:38 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'BOT_NAME': 'GoodReadsScraper',\n",
      " 'FEED_EXPORT_ENCODING': 'utf-8',\n",
      " 'NEWSPIDER_MODULE': 'GoodReadsScraper.spiders',\n",
      " 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\n",
      " 'ROBOTSTXT_OBEY': True,\n",
      " 'SPIDER_LOADER_WARN_ONLY': True,\n",
      " 'SPIDER_MODULES': ['GoodReadsScraper.spiders'],\n",
      " 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}\n",
      "2023-10-29 18:14:38 [asyncio] DEBUG: Using selector: SelectSelector\n",
      "2023-10-29 18:14:38 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\n",
      "2023-10-29 18:14:38 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop\n",
      "2023-10-29 18:14:38 [scrapy.extensions.telnet] INFO: Telnet Password: a7be4eb2b88dc69a\n",
      "2023-10-29 18:14:38 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2023-10-29 18:14:38 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2023-10-29 18:14:38 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2023-10-29 18:14:38 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2023-10-29 18:14:38 [scrapy.core.engine] INFO: Spider opened\n",
      "2023-10-29 18:14:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2023-10-29 18:14:38 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2023-10-29 18:14:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.goodreads.com/robots.txt> (referer: None)\n",
      "2023-10-29 18:14:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.goodreads.com/shelf/show/fiction> (referer: None)\n",
      "2023-10-29 18:14:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.goodreads.com/book/show/61439040-1984> (referer: https://www.goodreads.com/shelf/show/fiction)\n",
      "2023-10-29 18:14:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.goodreads.com/book/show/18144590-the-alchemist> (referer: https://www.goodreads.com/shelf/show/fiction)\n",
      "2023-10-29 18:14:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.goodreads.com/book/show/2657.To_Kill_a_Mockingbird> (referer: https://www.goodreads.com/shelf/show/fiction)\n",
      "2023-10-29 18:14:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.goodreads.com/book/show/4671.The_Great_Gatsby> (referer: https://www.goodreads.com/shelf/show/fiction)\n",
      "2023-10-29 18:14:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.goodreads.com/book/show/2767052-the-hunger-games> (referer: https://www.goodreads.com/shelf/show/fiction)\n",
      "2023-10-29 18:14:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.goodreads.com/book/show/38447.The_Handmaid_s_Tale> (referer: https://www.goodreads.com/shelf/show/fiction)\n",
      "2023-10-29 18:14:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.goodreads.com/book/show/72193.Harry_Potter_and_the_Philosopher_s_Stone> (referer: https://www.goodreads.com/shelf/show/fiction)\n",
      "2023-10-29 18:14:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.goodreads.com/book/show/5107.The_Catcher_in_the_Rye> (referer: https://www.goodreads.com/shelf/show/fiction)\n",
      "2023-10-29 18:14:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.goodreads.com/book/show/170448.Animal_Farm> (referer: https://www.goodreads.com/shelf/show/fiction)\n",
      "2023-10-29 18:14:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.goodreads.com/book/show/968.The_Da_Vinci_Code> (referer: https://www.goodreads.com/shelf/show/fiction)\n",
      "2023-10-29 18:14:44 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2023-10-29 18:14:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 5042,\n",
      " 'downloader/request_count': 12,\n",
      " 'downloader/request_method_count/GET': 12,\n",
      " 'downloader/response_bytes': 7745531,\n",
      " 'downloader/response_count': 12,\n",
      " 'downloader/response_status_count/200': 12,\n",
      " 'elapsed_time_seconds': 5.40392,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2023, 10, 29, 23, 14, 44, 342014),\n",
      " 'httpcompression/response_bytes': 282116,\n",
      " 'httpcompression/response_count': 2,\n",
      " 'log_count/DEBUG': 15,\n",
      " 'log_count/INFO': 10,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 12,\n",
      " 'robotstxt/request_count': 1,\n",
      " 'robotstxt/response_count': 1,\n",
      " 'robotstxt/response_status_count/200': 1,\n",
      " 'scheduler/dequeued': 11,\n",
      " 'scheduler/dequeued/memory': 11,\n",
      " 'scheduler/enqueued': 11,\n",
      " 'scheduler/enqueued/memory': 11,\n",
      " 'start_time': datetime.datetime(2023, 10, 29, 23, 14, 38, 938094)}\n",
      "2023-10-29 18:14:44 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "!scrapy runspider GoodReadsSpider.py -O ../../ejercicio0.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5dac09",
   "metadata": {},
   "source": [
    "# Pre-procesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09c117b",
   "metadata": {},
   "source": [
    "## Leer archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e8108b30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To Kill a Mockingbird\n",
      "The unforgettable novel of a childhood in a sleepy Southern town and the crisis of conscience that rocked it. \"To Kill A Mockingbird\" became both an instant bestseller and a critical success when it was first published in 1960. It went on to win the Pulitzer Prize in 1961 and was later made into an Academy Award-winning film, also a classic.\n"
     ]
    }
   ],
   "source": [
    "path = 'C:\\\\Users\\\\dgbla\\\\GitHub\\\\LibreriaUNAL\\\\Trabajo 2\\\\archivos\\\\4.txt'\n",
    "with open(path, 'r') as f:\n",
    "    file = f.readlines()\n",
    "title = file[0][:-1]\n",
    "synopsis = \" \".join(file[1::])\n",
    "print(title)\n",
    "print(synopsis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfd126b",
   "metadata": {},
   "source": [
    "## Poner todo en minuscula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c2095d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the unforgettable novel of a childhood in a sleepy southern town and the crisis of conscience that rocked it. \"to kill a mockingbird\" became both an instant bestseller and a critical success when it was first published in 1960. it went on to win the pulitzer prize in 1961 and was later made into an academy award-winning film, also a classic.\n"
     ]
    }
   ],
   "source": [
    "lower_text = synopsis.lower()\n",
    "print(lower_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97e0018",
   "metadata": {},
   "source": [
    "## Eliminar signos de Puntuacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9e91096b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the unforgettable novel of a childhood in a sleepy southern town and the crisis of conscience that rocked it to kill a mockingbird became both an instant bestseller and a critical success when it was first published in 1960 it went on to win the pulitzer prize in 1961 and was later made into an academy award-winning film also a classic\n"
     ]
    }
   ],
   "source": [
    "nlp = es_core_news_sm.load()\n",
    "doc = nlp(lower_text)\n",
    "tokens=[]\n",
    "# revision de signos de puntuacion y en caso de que no sea se agrega\n",
    "for token in doc:\n",
    "  if token.is_punct==False:\n",
    "    tokens.append(token.text)\n",
    "\n",
    "clean_text = \" \".join(tokens)\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40da9fec",
   "metadata": {},
   "source": [
    "## Eliminar las Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "62c9dd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add(\"\\\"\")\n",
    "stop_words.add(\"'\")\n",
    "stop_words.add(\"’\")\n",
    "stop_words.add(\"”\")\n",
    "stop_words.add(\"!\")\n",
    "stop_words.add(\"“\")\n",
    "stop_words.add(\"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "752502dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'unforgettable', 'novel', 'of', 'a', 'childhood', 'in', 'a', 'sleepy', 'southern', 'town', 'and', 'the', 'crisis', 'of', 'conscience', 'that', 'rocked', 'it', 'to', 'kill', 'a', 'mockingbird', 'became', 'both', 'an', 'instant', 'bestseller', 'and', 'a', 'critical', 'success', 'when', 'it', 'was', 'first', 'published', 'in', '1960', 'it', 'went', 'on', 'to', 'win', 'the', 'pulitzer', 'prize', 'in', '1961', 'and', 'was', 'later', 'made', 'into', 'an', 'academy', 'award-winning', 'film', 'also', 'a', 'classic']\n",
      "['unforgettable', 'novel', 'childhood', 'sleepy', 'southern', 'town', 'crisis', 'conscience', 'rocked', 'kill', 'mockingbird', 'became', 'instant', 'bestseller', 'critical', 'success', 'first', 'published', '1960', 'went', 'win', 'pulitzer', 'prize', '1961', 'later', 'made', 'academy', 'award-winning', 'film', 'also', 'classic']\n",
      "unforgettable novel childhood sleepy southern town crisis conscience rocked kill mockingbird became instant bestseller critical success first published 1960 went win pulitzer prize 1961 later made academy award-winning film also classic\n"
     ]
    }
   ],
   "source": [
    "new_tokens = word_tokenize(clean_text)\n",
    "print(new_tokens)\n",
    "clean_tokens = [w for w in new_tokens if not w in stop_words]\n",
    "print(clean_tokens)\n",
    "final_text = \" \".join(clean_tokens)\n",
    "print(final_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bc3e14",
   "metadata": {},
   "source": [
    "## Guardar archivo modificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2a04df52",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\dgbla\\\\GitHub\\\\LibreriaUNAL\\\\Trabajo 2\\\\archivos-clean\\\\3.txt'\n",
    "with open(path, 'w') as f:\n",
    "    f.write(f'{title}\\n{final_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf569116",
   "metadata": {},
   "source": [
    "# Vectorizacion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ad141a",
   "metadata": {},
   "source": [
    "## Dataframe of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b274030a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ddb3eb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "current = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "483a6a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = set(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7acb801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zvect = [0] * df.shape[0]\n",
    "for p in c:\n",
    "    if p not in current:\n",
    "        df[p] = zvect\n",
    "        current.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2edc3a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict()\n",
    "for it in current:\n",
    "    if it in c:\n",
    "        sum = clean_tokens.count(it)\n",
    "        d[it] = sum/len(clean_tokens)\n",
    "    else:\n",
    "        d[it] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d7187742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>capitol</th>\n",
       "      <th>ruins</th>\n",
       "      <th>north</th>\n",
       "      <th>panem</th>\n",
       "      <th>annual</th>\n",
       "      <th>keeps</th>\n",
       "      <th>tv</th>\n",
       "      <th>live</th>\n",
       "      <th>one</th>\n",
       "      <th>hunger</th>\n",
       "      <th>...</th>\n",
       "      <th>classic</th>\n",
       "      <th>kill</th>\n",
       "      <th>rocked</th>\n",
       "      <th>childhood</th>\n",
       "      <th>went</th>\n",
       "      <th>mockingbird</th>\n",
       "      <th>success</th>\n",
       "      <th>later</th>\n",
       "      <th>film</th>\n",
       "      <th>bestseller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    capitol     ruins     north     panem    annual     keeps        tv  \\\n",
       "0  0.054054  0.027027  0.027027  0.027027  0.027027  0.027027  0.027027   \n",
       "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "       live       one    hunger  ...   classic      kill    rocked  childhood  \\\n",
       "0  0.027027  0.054054  0.027027  ...  0.000000  0.000000  0.000000   0.000000   \n",
       "1       NaN       NaN       NaN  ...  0.032258  0.032258  0.032258   0.032258   \n",
       "\n",
       "       went  mockingbird   success     later      film  bestseller  \n",
       "0  0.000000     0.000000  0.000000  0.000000  0.000000    0.000000  \n",
       "1  0.032258     0.032258  0.032258  0.032258  0.032258    0.032258  \n",
       "\n",
       "[2 rows x 64 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c098858c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>capitol</th>\n",
       "      <th>ruins</th>\n",
       "      <th>north</th>\n",
       "      <th>panem</th>\n",
       "      <th>annual</th>\n",
       "      <th>keeps</th>\n",
       "      <th>tv</th>\n",
       "      <th>live</th>\n",
       "      <th>one</th>\n",
       "      <th>hunger</th>\n",
       "      <th>...</th>\n",
       "      <th>classic</th>\n",
       "      <th>kill</th>\n",
       "      <th>rocked</th>\n",
       "      <th>childhood</th>\n",
       "      <th>went</th>\n",
       "      <th>mockingbird</th>\n",
       "      <th>success</th>\n",
       "      <th>later</th>\n",
       "      <th>film</th>\n",
       "      <th>bestseller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    capitol     ruins     north     panem    annual     keeps        tv  \\\n",
       "0  0.054054  0.027027  0.027027  0.027027  0.027027  0.027027  0.027027   \n",
       "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       live       one    hunger  ...   classic      kill    rocked  childhood  \\\n",
       "0  0.027027  0.054054  0.027027  ...  0.000000  0.000000  0.000000   0.000000   \n",
       "1       NaN       NaN       NaN  ...  0.032258  0.032258  0.032258   0.032258   \n",
       "2  0.000000  0.000000  0.000000  ...  0.032258  0.032258  0.032258   0.032258   \n",
       "\n",
       "       went  mockingbird   success     later      film  bestseller  \n",
       "0  0.000000     0.000000  0.000000  0.000000  0.000000    0.000000  \n",
       "1  0.032258     0.032258  0.032258  0.032258  0.032258    0.032258  \n",
       "2  0.032258     0.032258  0.032258  0.032258  0.032258    0.032258  \n",
       "\n",
       "[3 rows x 64 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_record = pd.DataFrame([d])\n",
    "df = pd.concat([df, new_record], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b589fd5",
   "metadata": {},
   "source": [
    "# Base de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4b1b5e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crisis</th>\n",
       "      <th>became</th>\n",
       "      <th>published</th>\n",
       "      <th>pulitzer</th>\n",
       "      <th>award-winning</th>\n",
       "      <th>town</th>\n",
       "      <th>1961</th>\n",
       "      <th>southern</th>\n",
       "      <th>made</th>\n",
       "      <th>instant</th>\n",
       "      <th>...</th>\n",
       "      <th>classic</th>\n",
       "      <th>kill</th>\n",
       "      <th>rocked</th>\n",
       "      <th>childhood</th>\n",
       "      <th>went</th>\n",
       "      <th>mockingbird</th>\n",
       "      <th>success</th>\n",
       "      <th>later</th>\n",
       "      <th>film</th>\n",
       "      <th>bestseller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     crisis    became  published  pulitzer  award-winning      town      1961  \\\n",
       "0  0.032258  0.032258   0.032258  0.032258       0.032258  0.032258  0.032258   \n",
       "1  0.032258  0.032258   0.032258  0.032258       0.032258  0.032258  0.032258   \n",
       "2  0.032258  0.032258   0.032258  0.032258       0.032258  0.032258  0.032258   \n",
       "3  0.032258  0.032258   0.032258  0.032258       0.032258  0.032258  0.032258   \n",
       "4  0.032258  0.032258   0.032258  0.032258       0.032258  0.032258  0.032258   \n",
       "5  0.032258  0.032258   0.032258  0.032258       0.032258  0.032258  0.032258   \n",
       "6  0.032258  0.032258   0.032258  0.032258       0.032258  0.032258  0.032258   \n",
       "7  0.032258  0.032258   0.032258  0.032258       0.032258  0.032258  0.032258   \n",
       "8  0.032258  0.032258   0.032258  0.032258       0.032258  0.032258  0.032258   \n",
       "9  0.032258  0.032258   0.032258  0.032258       0.032258  0.032258  0.032258   \n",
       "\n",
       "   southern      made   instant  ...   classic      kill    rocked  childhood  \\\n",
       "0  0.032258  0.032258  0.032258  ...  0.032258  0.032258  0.032258   0.032258   \n",
       "1  0.032258  0.032258  0.032258  ...  0.032258  0.032258  0.032258   0.032258   \n",
       "2  0.032258  0.032258  0.032258  ...  0.032258  0.032258  0.032258   0.032258   \n",
       "3  0.032258  0.032258  0.032258  ...  0.032258  0.032258  0.032258   0.032258   \n",
       "4  0.032258  0.032258  0.032258  ...  0.032258  0.032258  0.032258   0.032258   \n",
       "5  0.032258  0.032258  0.032258  ...  0.032258  0.032258  0.032258   0.032258   \n",
       "6  0.032258  0.032258  0.032258  ...  0.032258  0.032258  0.032258   0.032258   \n",
       "7  0.032258  0.032258  0.032258  ...  0.032258  0.032258  0.032258   0.032258   \n",
       "8  0.032258  0.032258  0.032258  ...  0.032258  0.032258  0.032258   0.032258   \n",
       "9  0.032258  0.032258  0.032258  ...  0.032258  0.032258  0.032258   0.032258   \n",
       "\n",
       "       went  mockingbird   success     later      film  bestseller  \n",
       "0  0.032258     0.032258  0.032258  0.032258  0.032258    0.032258  \n",
       "1  0.032258     0.032258  0.032258  0.032258  0.032258    0.032258  \n",
       "2  0.032258     0.032258  0.032258  0.032258  0.032258    0.032258  \n",
       "3  0.032258     0.032258  0.032258  0.032258  0.032258    0.032258  \n",
       "4  0.032258     0.032258  0.032258  0.032258  0.032258    0.032258  \n",
       "5  0.032258     0.032258  0.032258  0.032258  0.032258    0.032258  \n",
       "6  0.032258     0.032258  0.032258  0.032258  0.032258    0.032258  \n",
       "7  0.032258     0.032258  0.032258  0.032258  0.032258    0.032258  \n",
       "8  0.032258     0.032258  0.032258  0.032258  0.032258    0.032258  \n",
       "9  0.032258     0.032258  0.032258  0.032258  0.032258    0.032258  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for p in range(1,11):\n",
    "    path = 'C:\\\\Users\\\\dgbla\\\\GitHub\\\\LibreriaUNAL\\\\Trabajo 2\\\\archivos\\\\' + str(p) + '.txt'\n",
    "    id, clean = preProcess(path)\n",
    "    df = vect(df, id, clean)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3affaa",
   "metadata": {},
   "source": [
    "# Consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f436f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4370b31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
