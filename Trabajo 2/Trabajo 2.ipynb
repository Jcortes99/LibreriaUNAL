{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c33f0c5",
   "metadata": {},
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e5d0ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scrapy\n",
      "  Obtaining dependency information for scrapy from https://files.pythonhosted.org/packages/08/66/22ed9609df4b6d94a66512572a11b35943a6cb36dc268f88ebfbede60be1/Scrapy-2.11.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading Scrapy-2.11.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting Twisted<23.8.0,>=18.9.0 (from scrapy)\n",
      "  Downloading Twisted-22.10.0-py3-none-any.whl (3.1 MB)\n",
      "     ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.1 MB 435.7 kB/s eta 0:00:08\n",
      "     - -------------------------------------- 0.1/3.1 MB 880.9 kB/s eta 0:00:04\n",
      "     --- ------------------------------------ 0.3/3.1 MB 2.2 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 0.5/3.1 MB 3.1 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 1.0/3.1 MB 4.7 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 1.5/3.1 MB 6.0 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 2.0/3.1 MB 6.7 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 2.4/3.1 MB 7.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 2.9/3.1 MB 7.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.1/3.1 MB 7.7 MB/s eta 0:00:00\n",
      "Collecting cryptography>=36.0.0 (from scrapy)\n",
      "  Obtaining dependency information for cryptography>=36.0.0 from https://files.pythonhosted.org/packages/86/35/f03a42444866ef7f23134812a05012dcb509418214fb78ec848f28cd14b8/cryptography-41.0.5-cp37-abi3-win_amd64.whl.metadata\n",
      "  Downloading cryptography-41.0.5-cp37-abi3-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting cssselect>=0.9.1 (from scrapy)\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting itemloaders>=1.0.1 (from scrapy)\n",
      "  Downloading itemloaders-1.1.0-py3-none-any.whl (11 kB)\n",
      "Collecting parsel>=1.5.0 (from scrapy)\n",
      "  Downloading parsel-1.8.1-py2.py3-none-any.whl (17 kB)\n",
      "Collecting pyOpenSSL>=21.0.0 (from scrapy)\n",
      "  Obtaining dependency information for pyOpenSSL>=21.0.0 from https://files.pythonhosted.org/packages/db/de/007b832ad7a95e6a73745609bbe123c407aa2c46bb0b8f765c8718294e7f/pyOpenSSL-23.3.0-py3-none-any.whl.metadata\n",
      "  Downloading pyOpenSSL-23.3.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting queuelib>=1.4.2 (from scrapy)\n",
      "  Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n",
      "Collecting service-identity>=18.1.0 (from scrapy)\n",
      "  Obtaining dependency information for service-identity>=18.1.0 from https://files.pythonhosted.org/packages/0c/42/bf07f277b45da6e350df3314804aa2b5411e0938d3b78b4f17da2e1302c2/service_identity-23.1.0-py3-none-any.whl.metadata\n",
      "  Downloading service_identity-23.1.0-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting w3lib>=1.17.0 (from scrapy)\n",
      "  Obtaining dependency information for w3lib>=1.17.0 from https://files.pythonhosted.org/packages/82/e2/dcf8573d7153194eb673347cea1f9bbdb2a8e61030740fb6f50e4234a00b/w3lib-2.1.2-py3-none-any.whl.metadata\n",
      "  Downloading w3lib-2.1.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting zope.interface>=5.1.0 (from scrapy)\n",
      "  Obtaining dependency information for zope.interface>=5.1.0 from https://files.pythonhosted.org/packages/0f/d5/81f9789311d9773a02ed048af7452fc6cedce059748dba956c1dc040340a/zope.interface-6.1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading zope.interface-6.1-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "     ---------------------------------------- 0.0/42.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.8/42.8 kB ? eta 0:00:00\n",
      "Collecting protego>=0.1.15 (from scrapy)\n",
      "  Obtaining dependency information for protego>=0.1.15 from https://files.pythonhosted.org/packages/bc/16/14fd1ecdece2e1d87279fc09fbd2d55bae5fa033783c3547af631c74d718/Protego-0.3.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading Protego-0.3.0-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting itemadapter>=0.1.0 (from scrapy)\n",
      "  Downloading itemadapter-0.8.0-py3-none-any.whl (11 kB)\n",
      "Collecting setuptools (from scrapy)\n",
      "  Obtaining dependency information for setuptools from https://files.pythonhosted.org/packages/bb/26/7945080113158354380a12ce26873dd6c1ebd88d47f5bc24e2c5bb38c16a/setuptools-68.2.2-py3-none-any.whl.metadata\n",
      "  Downloading setuptools-68.2.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\usuario\\appdata\\roaming\\python\\python312\\site-packages (from scrapy) (23.2)\n",
      "Collecting tldextract (from scrapy)\n",
      "  Obtaining dependency information for tldextract from https://files.pythonhosted.org/packages/75/c0/038a9529d1b3cf10ab682bb66e2e253530e5380c2b656205703d9f618b30/tldextract-5.0.1-py3-none-any.whl.metadata\n",
      "  Downloading tldextract-5.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting lxml>=4.4.1 (from scrapy)\n",
      "  Obtaining dependency information for lxml>=4.4.1 from https://files.pythonhosted.org/packages/77/e5/1f23e56678244258483521872507d64130cac9466902aca3f3141b8fb06b/lxml-4.9.3-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading lxml-4.9.3-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting PyDispatcher>=2.0.5 (from scrapy)\n",
      "  Downloading PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n",
      "Collecting cffi>=1.12 (from cryptography>=36.0.0->scrapy)\n",
      "  Obtaining dependency information for cffi>=1.12 from https://files.pythonhosted.org/packages/e9/63/e285470a4880a4f36edabe4810057bd4b562c6ddcc165eacf9c3c7210b40/cffi-1.16.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading cffi-1.16.0-cp312-cp312-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting jmespath>=0.9.5 (from itemloaders>=1.0.1->scrapy)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting attrs>=19.1.0 (from service-identity>=18.1.0->scrapy)\n",
      "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "     ---------------------------------------- 0.0/61.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.2/61.2 kB 3.2 MB/s eta 0:00:00\n",
      "Collecting pyasn1 (from service-identity>=18.1.0->scrapy)\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "     ---------------------------------------- 0.0/83.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 83.9/83.9 kB 4.6 MB/s eta 0:00:00\n",
      "Collecting pyasn1-modules (from service-identity>=18.1.0->scrapy)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "     ---------------------------------------- 0.0/181.3 kB ? eta -:--:--\n",
      "     ------------------------------------- 181.3/181.3 kB 11.4 MB/s eta 0:00:00\n",
      "Collecting constantly>=15.1 (from Twisted<23.8.0,>=18.9.0->scrapy)\n",
      "  Obtaining dependency information for constantly>=15.1 from https://files.pythonhosted.org/packages/b8/40/c199d095151addf69efdb4b9ca3a4f20f70e20508d6222bffb9b76f58573/constantly-23.10.4-py3-none-any.whl.metadata\n",
      "  Downloading constantly-23.10.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting incremental>=21.3.0 (from Twisted<23.8.0,>=18.9.0->scrapy)\n",
      "  Downloading incremental-22.10.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting Automat>=0.8.0 (from Twisted<23.8.0,>=18.9.0->scrapy)\n",
      "  Downloading Automat-22.10.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting hyperlink>=17.1.1 (from Twisted<23.8.0,>=18.9.0->scrapy)\n",
      "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
      "     ---------------------------------------- 0.0/74.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 74.6/74.6 kB 4.0 MB/s eta 0:00:00\n",
      "Collecting typing-extensions>=3.6.5 (from Twisted<23.8.0,>=18.9.0->scrapy)\n",
      "  Obtaining dependency information for typing-extensions>=3.6.5 from https://files.pythonhosted.org/packages/24/21/7d397a4b7934ff4028987914ac1044d3b7d52712f30e2ac7a2ae5bc86dd0/typing_extensions-4.8.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting twisted-iocpsupport<2,>=1.0.2 (from Twisted<23.8.0,>=18.9.0->scrapy)\n",
      "  Obtaining dependency information for twisted-iocpsupport<2,>=1.0.2 from https://files.pythonhosted.org/packages/f3/9d/3813cd573dff68426e0ab0f9f47c7876dd9d98238e55aefa019c89c400b9/twisted_iocpsupport-1.0.4-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading twisted_iocpsupport-1.0.4-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting idna (from tldextract->scrapy)\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "     ---------------------------------------- 0.0/61.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.5/61.5 kB 3.2 MB/s eta 0:00:00\n",
      "Collecting requests>=2.1.0 (from tldextract->scrapy)\n",
      "  Obtaining dependency information for requests>=2.1.0 from https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl.metadata\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting requests-file>=1.4 (from tldextract->scrapy)\n",
      "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
      "Collecting filelock>=3.0.8 (from tldextract->scrapy)\n",
      "  Obtaining dependency information for filelock>=3.0.8 from https://files.pythonhosted.org/packages/81/54/84d42a0bee35edba99dee7b59a8d4970eccdd44b99fe728ed912106fc781/filelock-3.13.1-py3-none-any.whl.metadata\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: six in c:\\users\\usuario\\appdata\\roaming\\python\\python312\\site-packages (from Automat>=0.8.0->Twisted<23.8.0,>=18.9.0->scrapy) (1.16.0)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=36.0.0->scrapy)\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "     ---------------------------------------- 0.0/118.7 kB ? eta -:--:--\n",
      "     -------------------------------------- 118.7/118.7 kB 7.2 MB/s eta 0:00:00\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.1.0->tldextract->scrapy)\n",
      "  Obtaining dependency information for charset-normalizer<4,>=2 from https://files.pythonhosted.org/packages/b2/a5/d52c61864fea4b02ef11da0a2e829ea7b365e09fae2a132314541ad01ae4/charset_normalizer-3.3.1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading charset_normalizer-3.3.1-cp312-cp312-win_amd64.whl.metadata (33 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.1.0->tldextract->scrapy)\n",
      "  Obtaining dependency information for urllib3<3,>=1.21.1 from https://files.pythonhosted.org/packages/d2/b2/b157855192a68541a91ba7b2bbcb91f1b4faa51f8bae38d8005c034be524/urllib3-2.0.7-py3-none-any.whl.metadata\n",
      "  Downloading urllib3-2.0.7-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.1.0->tldextract->scrapy)\n",
      "  Obtaining dependency information for certifi>=2017.4.17 from https://files.pythonhosted.org/packages/4c/dd/2234eab22353ffc7d94e8d13177aaa050113286e93e7b40eae01fbf7c3d9/certifi-2023.7.22-py3-none-any.whl.metadata\n",
      "  Downloading certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\n",
      "Downloading Scrapy-2.11.0-py2.py3-none-any.whl (286 kB)\n",
      "   ---------------------------------------- 0.0/286.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 286.4/286.4 kB 5.9 MB/s eta 0:00:00\n",
      "Downloading cryptography-41.0.5-cp37-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.7 MB 9.8 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.0/2.7 MB 12.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.4/2.7 MB 11.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.9/2.7 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.3/2.7 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 10.6 MB/s eta 0:00:00\n",
      "Downloading lxml-4.9.3-cp312-cp312-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.5/3.8 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 1.0/3.8 MB 12.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.4/3.8 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.8/3.8 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 2.4/3.8 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.7/3.8 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.7/3.8 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.7/3.8 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 10.9 MB/s eta 0:00:00\n",
      "Downloading Protego-0.3.0-py2.py3-none-any.whl (8.5 kB)\n",
      "Downloading pyOpenSSL-23.3.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.8/58.8 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading service_identity-23.1.0-py3-none-any.whl (12 kB)\n",
      "Downloading w3lib-2.1.2-py3-none-any.whl (21 kB)\n",
      "Downloading zope.interface-6.1-cp312-cp312-win_amd64.whl (204 kB)\n",
      "   ---------------------------------------- 0.0/204.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 204.3/204.3 kB 6.3 MB/s eta 0:00:00\n",
      "Downloading setuptools-68.2.2-py3-none-any.whl (807 kB)\n",
      "   ---------------------------------------- 0.0/807.9 kB ? eta -:--:--\n",
      "   -------------------- ------------------ 419.8/807.9 kB 13.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  798.7/807.9 kB 12.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 807.9/807.9 kB 12.7 MB/s eta 0:00:00\n",
      "Downloading tldextract-5.0.1-py3-none-any.whl (97 kB)\n",
      "   ---------------------------------------- 0.0/97.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 97.1/97.1 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading cffi-1.16.0-cp312-cp312-win_amd64.whl (181 kB)\n",
      "   ---------------------------------------- 0.0/182.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 182.0/182.0 kB ? eta 0:00:00\n",
      "Downloading constantly-23.10.4-py3-none-any.whl (13 kB)\n",
      "Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.6/62.6 kB ? eta 0:00:00\n",
      "Downloading twisted_iocpsupport-1.0.4-cp312-cp312-win_amd64.whl (47 kB)\n",
      "   ---------------------------------------- 0.0/47.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 47.6/47.6 kB ? eta 0:00:00\n",
      "Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "   ---------------------------------------- 0.0/158.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 158.3/158.3 kB 9.9 MB/s eta 0:00:00\n",
      "Downloading charset_normalizer-3.3.1-cp312-cp312-win_amd64.whl (98 kB)\n",
      "   ---------------------------------------- 0.0/98.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 98.8/98.8 kB 5.9 MB/s eta 0:00:00\n",
      "Downloading urllib3-2.0.7-py3-none-any.whl (124 kB)\n",
      "   ---------------------------------------- 0.0/124.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 124.2/124.2 kB ? eta 0:00:00\n",
      "Installing collected packages: twisted-iocpsupport, PyDispatcher, incremental, w3lib, urllib3, typing-extensions, setuptools, queuelib, pycparser, pyasn1, protego, lxml, jmespath, itemadapter, idna, filelock, cssselect, constantly, charset-normalizer, certifi, attrs, zope.interface, requests, pyasn1-modules, parsel, hyperlink, cffi, Automat, Twisted, requests-file, itemloaders, cryptography, tldextract, service-identity, pyOpenSSL, scrapy\n",
      "Successfully installed Automat-22.10.0 PyDispatcher-2.0.7 Twisted-22.10.0 attrs-23.1.0 certifi-2023.7.22 cffi-1.16.0 charset-normalizer-3.3.1 constantly-23.10.4 cryptography-41.0.5 cssselect-1.2.0 filelock-3.13.1 hyperlink-21.0.0 idna-3.4 incremental-22.10.0 itemadapter-0.8.0 itemloaders-1.1.0 jmespath-1.0.1 lxml-4.9.3 parsel-1.8.1 protego-0.3.0 pyOpenSSL-23.3.0 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycparser-2.21 queuelib-1.6.2 requests-2.31.0 requests-file-1.5.1 scrapy-2.11.0 service-identity-23.1.0 setuptools-68.2.2 tldextract-5.0.1 twisted-iocpsupport-1.0.4 typing-extensions-4.8.0 urllib3-2.0.7 w3lib-2.1.2 zope.interface-6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script normalizer.exe is installed in 'c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script automat-visualize.exe is installed in 'c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts cftp.exe, ckeygen.exe, conch.exe, mailmail.exe, pyhtmlizer.exe, tkconch.exe, trial.exe, twist.exe and twistd.exe are installed in 'c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tldextract.exe is installed in 'c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script scrapy.exe is installed in 'c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Obtaining dependency information for spacy from https://files.pythonhosted.org/packages/13/e7/31226298e99a7babec707d2badb1ae0b9f94e262199f57faf08ed899f4ef/spacy-3.7.2-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading spacy-3.7.2-cp312-cp312-win_amd64.whl.metadata (26 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Obtaining dependency information for spacy-loggers<2.0.0,>=1.0.0 from https://files.pythonhosted.org/packages/33/78/d1a1a026ef3af911159398c939b1509d5c36fe524c7b644f34a5146c4e16/spacy_loggers-1.0.5-py3-none-any.whl.metadata\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Obtaining dependency information for murmurhash<1.1.0,>=0.28.0 from https://files.pythonhosted.org/packages/3b/56/8630be974aeb05868f2058db0ce6f19d85c27adb9b8f733cf69c856afdaa/murmurhash-1.0.10-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading murmurhash-1.0.10-cp312-cp312-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Obtaining dependency information for cymem<2.1.0,>=2.0.2 from https://files.pythonhosted.org/packages/35/e0/34b11adc80502f0760ce2892dfdfcd8a7f450acd3147156c98620cb4071d/cymem-2.0.8-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading cymem-2.0.8-cp312-cp312-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Obtaining dependency information for preshed<3.1.0,>=3.0.2 from https://files.pythonhosted.org/packages/db/e4/d074efb7e8a8873d346d2fb8dd43e19b1eae0697351c0d79cff947cba46e/preshed-3.0.9-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading preshed-3.0.9-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.1.8 (from spacy)\n",
      "  Obtaining dependency information for thinc<8.3.0,>=8.1.8 from https://files.pythonhosted.org/packages/77/51/c40aa36f1835f187a5a727e1a3c2dcb44071a9f87ac2398352731fbed3fb/thinc-8.2.1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading thinc-8.2.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Obtaining dependency information for wasabi<1.2.0,>=0.9.1 from https://files.pythonhosted.org/packages/8f/69/26cbf0bad11703241cb84d5324d868097f7a8faf2f1888354dac8883f3fc/wasabi-1.1.2-py3-none-any.whl.metadata\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Obtaining dependency information for srsly<3.0.0,>=2.4.3 from https://files.pythonhosted.org/packages/06/b4/d620235df9104c9049c5378027fb2692a8a51fafc775e2feae815ff99599/srsly-2.4.8-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading srsly-2.4.8-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Obtaining dependency information for catalogue<2.1.0,>=2.0.6 from https://files.pythonhosted.org/packages/9e/96/d32b941a501ab566a16358d68b6eb4e4acc373fab3c3c4d7d9e649f7b4bb/catalogue-2.0.10-py3-none-any.whl.metadata\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0 (from spacy)\n",
      "  Obtaining dependency information for weasel<0.4.0,>=0.1.0 from https://files.pythonhosted.org/packages/a6/76/41433e70b7c9ed47db8206536ecc6408362db44111c27f59e76af20377f2/weasel-0.3.3-py3-none-any.whl.metadata\n",
      "  Downloading weasel-0.3.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "     ---------------------------------------- 0.0/45.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 45.9/45.9 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting smart-open<7.0.0,>=5.2.1 (from spacy)\n",
      "  Obtaining dependency information for smart-open<7.0.0,>=5.2.1 from https://files.pythonhosted.org/packages/fc/d9/d97f1db64b09278aba64e8c81b5d322d436132df5741c518f3823824fae0/smart_open-6.4.0-py3-none-any.whl.metadata\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting tqdm<5.0.0,>=4.38.0 (from spacy)\n",
      "  Obtaining dependency information for tqdm<5.0.0,>=4.38.0 from https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.6/57.6 kB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
      "  Obtaining dependency information for pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 from https://files.pythonhosted.org/packages/73/66/0a72c9fcde42e5650c8d8d5c5c1873b9a3893018020c77ca8eb62708b923/pydantic-2.4.2-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.4.2-py3-none-any.whl.metadata (158 kB)\n",
      "     ---------------------------------------- 0.0/158.6 kB ? eta -:--:--\n",
      "     -------------------------------------- 158.6/158.6 kB 9.3 MB/s eta 0:00:00\n",
      "Collecting jinja2 (from spacy)\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "     ---------------------------------------- 0.0/133.1 kB ? eta -:--:--\n",
      "     -------------------------------------- 133.1/133.1 kB 7.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\usuario\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (23.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "     ---------------------------------------- 0.0/181.6 kB ? eta -:--:--\n",
      "     ------------------------------------- 181.6/181.6 kB 11.4 MB/s eta 0:00:00\n",
      "Collecting numpy>=1.19.0 (from spacy)\n",
      "  Obtaining dependency information for numpy>=1.19.0 from https://files.pythonhosted.org/packages/32/95/908d0caa051beae4f7c77652dbbeb781e7b717f3040c5c5fcaed4d3ed08f/numpy-1.26.1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading numpy-1.26.1-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.2/61.2 kB ? eta 0:00:00\n",
      "Collecting annotated-types>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/28/78/d31230046e58c207284c6b2c4e8d96e6d3cb4e52354721b944d3e1ee4aa5/annotated_types-0.6.0-py3-none-any.whl.metadata\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.10.1 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Obtaining dependency information for pydantic-core==2.10.1 from https://files.pythonhosted.org/packages/a4/5e/f8436267bb9a35099a75237325107beb640a5a8c8b718492381e9b836719/pydantic_core-2.10.1-cp312-none-win_amd64.whl.metadata\n",
      "  Downloading pydantic_core-2.10.1-cp312-none-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.1.8->spacy)\n",
      "  Obtaining dependency information for blis<0.8.0,>=0.7.8 from https://files.pythonhosted.org/packages/9a/91/4aea63dccee6491a54c630d9817656a886e086ab97222e2d8101d8cdf894/blis-0.7.11-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading blis-0.7.11-cp312-cp312-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.1.8->spacy)\n",
      "  Obtaining dependency information for confection<1.0.0,>=0.0.1 from https://files.pythonhosted.org/packages/93/f8/e89268a1f885048fb2ee6b5c9f93c4e90de768534acfef3652f87d97d4cb/confection-0.1.3-py3-none-any.whl.metadata\n",
      "  Downloading confection-0.1.3-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\usuario\\appdata\\roaming\\python\\python312\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Collecting click<9.0.0,>=7.1.1 (from typer<0.10.0,>=0.3.0->spacy)\n",
      "  Obtaining dependency information for click<9.0.0,>=7.1.1 from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy)\n",
      "  Obtaining dependency information for cloudpathlib<0.17.0,>=0.7.0 from https://files.pythonhosted.org/packages/0f/6e/45b57a7d4573d85d0b0a39d99673dc1f5eea9d92a1a4603b35e968fbf89a/cloudpathlib-0.16.0-py3-none-any.whl.metadata\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->spacy)\n",
      "  Obtaining dependency information for MarkupSafe>=2.0 from https://files.pythonhosted.org/packages/44/44/dbaf65876e258facd65f586dde158387ab89963e7f2235551afc9c2e24c2/MarkupSafe-2.1.3-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading MarkupSafe-2.1.3-cp312-cp312-win_amd64.whl.metadata (3.0 kB)\n",
      "Downloading spacy-3.7.2-cp312-cp312-win_amd64.whl (11.7 MB)\n",
      "   ---------------------------------------- 0.0/11.7 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.7 MB 14.5 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 1.0/11.7 MB 13.3 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.5/11.7 MB 12.0 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.1/11.7 MB 12.1 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.1/11.7 MB 12.1 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.1/11.7 MB 12.1 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.1/11.7 MB 12.1 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.1/11.7 MB 12.1 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.1/11.7 MB 12.1 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.4/11.7 MB 5.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.9/11.7 MB 6.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.2/11.7 MB 6.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.7/11.7 MB 6.6 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.2/11.7 MB 7.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.2/11.7 MB 7.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.2/11.7 MB 7.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.2/11.7 MB 5.7 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.7/11.7 MB 6.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.1/11.7 MB 6.3 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.2/11.7 MB 6.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.7/11.7 MB 6.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.2/11.7 MB 6.5 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.7/11.7 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.2/11.7 MB 7.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.7/11.7 MB 7.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.1/11.7 MB 7.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.1/11.7 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.2/11.7 MB 7.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.7/11.7 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.1/11.7 MB 8.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.7/11.7 MB 8.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.2/11.7 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.7/11.7 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.7/11.7 MB 7.8 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp312-cp312-win_amd64.whl (39 kB)\n",
      "Downloading murmurhash-1.0.10-cp312-cp312-win_amd64.whl (25 kB)\n",
      "Downloading numpy-1.26.1-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.6/15.5 MB 12.9 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 1.1/15.5 MB 14.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.6/15.5 MB 12.7 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 2.1/15.5 MB 12.0 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.5/15.5 MB 12.4 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 3.0/15.5 MB 12.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.5/15.5 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 4.0/15.5 MB 12.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 4.5/15.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 5.0/15.5 MB 12.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 5.4/15.5 MB 12.0 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 5.9/15.5 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.5/15.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 7.0/15.5 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.5/15.5 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 8.0/15.5 MB 12.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 8.5/15.5 MB 12.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 8.9/15.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.4/15.5 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.9/15.5 MB 12.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.5/15.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 11.0/15.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.5/15.5 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.6/15.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.2/15.5 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.7/15.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.2/15.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.7/15.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.2/15.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.7/15.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.1/15.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.5 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 10.9 MB/s eta 0:00:00\n",
      "Downloading preshed-3.0.9-cp312-cp312-win_amd64.whl (122 kB)\n",
      "   ---------------------------------------- 0.0/122.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 122.4/122.4 kB 7.0 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
      "   ---------------------------------------- 0.0/395.8 kB ? eta -:--:--\n",
      "   ------------------------------------ -- 368.6/395.8 kB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 395.8/395.8 kB 8.2 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.10.1-cp312-none-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.0 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.0/2.0 MB 12.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.5/2.0 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.0/2.0 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 10.6 MB/s eta 0:00:00\n",
      "Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 0.0/57.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 57.0/57.0 kB 3.1 MB/s eta 0:00:00\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp312-cp312-win_amd64.whl (478 kB)\n",
      "   ---------------------------------------- 0.0/478.8 kB ? eta -:--:--\n",
      "   ------------------------------------ -- 450.6/478.8 kB 14.2 MB/s eta 0:00:01\n",
      "   --------------------------------------- 478.8/478.8 kB 10.0 MB/s eta 0:00:00\n",
      "Downloading thinc-8.2.1-cp312-cp312-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.4 MB 15.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.1/1.4 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 10.3 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.3/78.3 kB ? eta 0:00:00\n",
      "Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.3.3-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.8/49.8 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading blis-0.7.11-cp312-cp312-win_amd64.whl (6.6 MB)\n",
      "   ---------------------------------------- 0.0/6.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/6.6 MB 15.2 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.0/6.6 MB 12.3 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.4/6.6 MB 11.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.9/6.6 MB 12.0 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 2.1/6.6 MB 11.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 2.5/6.6 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.7/6.6 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.3/6.6 MB 10.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.8/6.6 MB 10.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.3/6.6 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.8/6.6 MB 10.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.3/6.6 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.8/6.6 MB 10.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.2/6.6 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.6/6.6 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.6/6.6 MB 10.3 MB/s eta 0:00:00\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "   ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 97.9/97.9 kB 5.5 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 45.0/45.0 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading confection-0.1.3-py3-none-any.whl (34 kB)\n",
      "Downloading MarkupSafe-2.1.3-cp312-cp312-win_amd64.whl (16 kB)\n",
      "Installing collected packages: cymem, wasabi, tqdm, spacy-loggers, spacy-legacy, smart-open, pydantic-core, numpy, murmurhash, MarkupSafe, langcodes, cloudpathlib, click, catalogue, annotated-types, typer, srsly, pydantic, preshed, jinja2, blis, confection, weasel, thinc, spacy\n",
      "Successfully installed MarkupSafe-2.1.3 annotated-types-0.6.0 blis-0.7.11 catalogue-2.0.10 click-8.1.7 cloudpathlib-0.16.0 confection-0.1.3 cymem-2.0.8 jinja2-3.1.2 langcodes-3.3.0 murmurhash-1.0.10 numpy-1.26.1 preshed-3.0.9 pydantic-2.4.2 pydantic-core-2.10.1 smart-open-6.4.0 spacy-3.7.2 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.1 tqdm-4.66.1 typer-0.9.0 wasabi-1.1.2 weasel-0.3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script f2py.exe is installed in 'c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script weasel.exe is installed in 'c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script spacy.exe is installed in 'c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.1/1.5 MB 544.7 kB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 0.2/1.5 MB 1.6 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 0.5/1.5 MB 2.7 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 1.0/1.5 MB 4.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 1.4/1.5 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 5.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Collecting joblib (from nltk)\n",
      "  Obtaining dependency information for joblib from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Obtaining dependency information for regex>=2021.8.3 from https://files.pythonhosted.org/packages/d3/10/6f2d5f8635d7714ad97ce6ade7a643358c4f3e45cde4ed12b7150734a8f3/regex-2023.10.3-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading regex-2023.10.3-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.0/42.0 kB ? eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\usuario\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading regex-2023.10.3-cp312-cp312-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/269.0 kB ? eta -:--:--\n",
      "   ----------------------------- --------- 204.8/269.0 kB 13.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 269.0/269.0 kB 4.2 MB/s eta 0:00:00\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 302.2/302.2 kB 18.2 MB/s eta 0:00:00\n",
      "Installing collected packages: regex, joblib, nltk\n",
      "Successfully installed joblib-1.3.2 nltk-3.8.1 regex-2023.10.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script nltk.exe is installed in 'c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting es-core-news-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
      "     ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/12.9 MB 330.3 kB/s eta 0:00:39\n",
      "     --------------------------------------- 0.1/12.9 MB 550.5 kB/s eta 0:00:24\n",
      "     - -------------------------------------- 0.3/12.9 MB 2.3 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 0.7/12.9 MB 4.2 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 1.2/12.9 MB 5.5 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 1.7/12.9 MB 6.4 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 2.2/12.9 MB 7.2 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 2.7/12.9 MB 7.7 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 3.2/12.9 MB 8.4 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.2/12.9 MB 8.0 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 4.1/12.9 MB 8.8 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.4/12.9 MB 8.9 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 5.1/12.9 MB 9.2 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 5.6/12.9 MB 9.6 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 6.1/12.9 MB 9.6 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 6.6/12.9 MB 9.8 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 7.1/12.9 MB 9.9 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 7.6/12.9 MB 9.9 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 8.1/12.9 MB 10.1 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 8.6/12.9 MB 10.1 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.0/12.9 MB 10.3 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.5/12.9 MB 10.3 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 10.0/12.9 MB 10.3 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 10.5/12.9 MB 11.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 11.1/12.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 11.6/12.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 12.0/12.9 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 12.5/12.9 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.9/12.9 MB 11.7 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.9/12.9 MB 11.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from es-core-news-sm==3.7.0) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.3.3)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\usuario\\appdata\\roaming\\python\\python312\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.26.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\usuario\\appdata\\roaming\\python\\python312\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.1.3)\n",
      "Installing collected packages: es-core-news-sm\n",
      "Successfully installed es-core-news-sm-3.7.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting es-core-news-md==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_md-3.7.0/es_core_news_md-3.7.0-py3-none-any.whl (42.3 MB)\n",
      "     ---------------------------------------- 0.0/42.3 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/42.3 MB 330.3 kB/s eta 0:02:08\n",
      "     --------------------------------------- 0.1/42.3 MB 525.1 kB/s eta 0:01:21\n",
      "     --------------------------------------- 0.1/42.3 MB 737.3 kB/s eta 0:00:58\n",
      "     ---------------------------------------- 0.3/42.3 MB 1.7 MB/s eta 0:00:25\n",
      "     ---------------------------------------- 0.5/42.3 MB 2.5 MB/s eta 0:00:17\n",
      "      --------------------------------------- 1.0/42.3 MB 4.0 MB/s eta 0:00:11\n",
      "     - -------------------------------------- 1.5/42.3 MB 5.1 MB/s eta 0:00:08\n",
      "     -- ------------------------------------- 2.1/42.3 MB 6.2 MB/s eta 0:00:07\n",
      "     -- ------------------------------------- 2.7/42.3 MB 7.0 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 3.2/42.3 MB 7.3 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 3.7/42.3 MB 7.9 MB/s eta 0:00:05\n",
      "     --- ------------------------------------ 4.2/42.3 MB 8.1 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 4.5/42.3 MB 8.2 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 4.5/42.3 MB 8.0 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 5.6/42.3 MB 8.7 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 5.7/42.3 MB 8.9 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 6.6/42.3 MB 9.1 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 7.0/42.3 MB 9.3 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 7.4/42.3 MB 9.5 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 8.0/42.3 MB 9.5 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 8.5/42.3 MB 9.4 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 9.0/42.3 MB 9.6 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 9.4/42.3 MB 9.7 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 10.0/42.3 MB 9.8 MB/s eta 0:00:04\n",
      "     --------- ----------------------------- 10.4/42.3 MB 11.5 MB/s eta 0:00:03\n",
      "     ---------- ---------------------------- 10.9/42.3 MB 11.7 MB/s eta 0:00:03\n",
      "     ---------- ---------------------------- 11.4/42.3 MB 11.7 MB/s eta 0:00:03\n",
      "     ---------- ---------------------------- 11.9/42.3 MB 11.7 MB/s eta 0:00:03\n",
      "     ----------- --------------------------- 12.5/42.3 MB 11.9 MB/s eta 0:00:03\n",
      "     ----------- --------------------------- 12.9/42.3 MB 11.7 MB/s eta 0:00:03\n",
      "     ------------ -------------------------- 13.4/42.3 MB 11.7 MB/s eta 0:00:03\n",
      "     ------------ -------------------------- 13.8/42.3 MB 11.7 MB/s eta 0:00:03\n",
      "     ------------- ------------------------- 14.2/42.3 MB 11.7 MB/s eta 0:00:03\n",
      "     ------------- ------------------------- 14.7/42.3 MB 11.9 MB/s eta 0:00:03\n",
      "     -------------- ------------------------ 15.2/42.3 MB 12.1 MB/s eta 0:00:03\n",
      "     -------------- ------------------------ 15.7/42.3 MB 11.7 MB/s eta 0:00:03\n",
      "     -------------- ------------------------ 16.2/42.3 MB 12.1 MB/s eta 0:00:03\n",
      "     --------------- ----------------------- 16.7/42.3 MB 11.9 MB/s eta 0:00:03\n",
      "     --------------- ----------------------- 17.2/42.3 MB 11.9 MB/s eta 0:00:03\n",
      "     ---------------- ---------------------- 17.7/42.3 MB 11.9 MB/s eta 0:00:03\n",
      "     ---------------- ---------------------- 18.2/42.3 MB 11.7 MB/s eta 0:00:03\n",
      "     ----------------- --------------------- 18.7/42.3 MB 11.9 MB/s eta 0:00:02\n",
      "     ----------------- --------------------- 19.2/42.3 MB 11.9 MB/s eta 0:00:02\n",
      "     ------------------ -------------------- 19.8/42.3 MB 11.9 MB/s eta 0:00:02\n",
      "     ------------------ -------------------- 20.3/42.3 MB 11.7 MB/s eta 0:00:02\n",
      "     ------------------- ------------------- 20.7/42.3 MB 11.9 MB/s eta 0:00:02\n",
      "     ------------------- ------------------- 21.2/42.3 MB 11.9 MB/s eta 0:00:02\n",
      "     ------------------- ------------------- 21.6/42.3 MB 11.9 MB/s eta 0:00:02\n",
      "     -------------------- ------------------ 22.2/42.3 MB 11.9 MB/s eta 0:00:02\n",
      "     -------------------- ------------------ 22.7/42.3 MB 11.7 MB/s eta 0:00:02\n",
      "     --------------------- ----------------- 23.1/42.3 MB 11.9 MB/s eta 0:00:02\n",
      "     --------------------- ----------------- 23.6/42.3 MB 11.9 MB/s eta 0:00:02\n",
      "     ---------------------- ---------------- 24.1/42.3 MB 11.7 MB/s eta 0:00:02\n",
      "     ---------------------- ---------------- 24.7/42.3 MB 11.7 MB/s eta 0:00:02\n",
      "     ----------------------- --------------- 25.2/42.3 MB 11.9 MB/s eta 0:00:02\n",
      "     ----------------------- --------------- 25.7/42.3 MB 11.9 MB/s eta 0:00:02\n",
      "     ------------------------ -------------- 26.1/42.3 MB 11.9 MB/s eta 0:00:02\n",
      "     ------------------------ -------------- 26.6/42.3 MB 11.9 MB/s eta 0:00:02\n",
      "     ------------------------ -------------- 27.1/42.3 MB 11.7 MB/s eta 0:00:02\n",
      "     ------------------------- ------------- 27.6/42.3 MB 11.9 MB/s eta 0:00:02\n",
      "     ------------------------- ------------- 28.1/42.3 MB 11.9 MB/s eta 0:00:02\n",
      "     -------------------------- ------------ 28.5/42.3 MB 11.9 MB/s eta 0:00:02\n",
      "     -------------------------- ------------ 29.0/42.3 MB 11.9 MB/s eta 0:00:02\n",
      "     --------------------------- ----------- 29.6/42.3 MB 11.9 MB/s eta 0:00:02\n",
      "     --------------------------- ----------- 30.1/42.3 MB 11.9 MB/s eta 0:00:02\n",
      "     ---------------------------- ---------- 30.6/42.3 MB 11.9 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 31.1/42.3 MB 11.9 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 31.5/42.3 MB 11.7 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 32.0/42.3 MB 11.9 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 32.5/42.3 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 33.1/42.3 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 33.6/42.3 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 34.0/42.3 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 34.5/42.3 MB 11.9 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 35.2/42.3 MB 11.9 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 35.3/42.3 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 35.8/42.3 MB 11.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 36.2/42.3 MB 11.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 36.6/42.3 MB 11.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 37.1/42.3 MB 11.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 37.6/42.3 MB 11.3 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 38.1/42.3 MB 11.3 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 38.6/42.3 MB 11.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 39.1/42.3 MB 11.3 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 39.5/42.3 MB 11.3 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 40.0/42.3 MB 11.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 40.5/42.3 MB 11.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 41.1/42.3 MB 11.3 MB/s eta 0:00:01\n",
      "     --------------------------------------  41.6/42.3 MB 11.3 MB/s eta 0:00:01\n",
      "     --------------------------------------  42.0/42.3 MB 11.3 MB/s eta 0:00:01\n",
      "     --------------------------------------  42.3/42.3 MB 11.3 MB/s eta 0:00:01\n",
      "     --------------------------------------  42.3/42.3 MB 11.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 42.3/42.3 MB 9.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from es-core-news-md==3.7.0) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.3.3)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\usuario\\appdata\\roaming\\python\\python312\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.26.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\usuario\\appdata\\roaming\\python\\python312\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.1.3)\n",
      "Installing collected packages: es-core-news-md\n",
      "Successfully installed es-core-news-md-3.7.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_md')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#Importar librerias de Scrappy\n",
    "%pip install scrapy\n",
    "%pip install spacy\n",
    "%pip install nltk\n",
    "#Importar librerias de spacy para español\n",
    "!python -m spacy download es_core_news_sm\n",
    "!python -m spacy download es_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "678f64f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Asegurarse que se tienen todas las librerias incluidas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import es_core_news_sm\n",
    "import es_core_news_md\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3c85f3",
   "metadata": {},
   "source": [
    "# Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d238981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add(\"\\\"\")\n",
    "stop_words.add(\"'\")\n",
    "stop_words.add(\"’\")\n",
    "stop_words.add(\"”\")\n",
    "stop_words.add(\"!\")\n",
    "stop_words.add(\"“\")\n",
    "stop_words.add(\"?\")\n",
    "\n",
    "def preProcess(path):\n",
    "    # LEE \n",
    "    with open(path, 'r') as f:\n",
    "        file = f.readlines()\n",
    "    \n",
    "    title = file[0][:-1]\n",
    "    synopsis = \" \".join(file[1::])\n",
    "\n",
    "    #Minusculas\n",
    "    lower_text = synopsis.lower()\n",
    "\n",
    "    #Eliminar signos de puntuación\n",
    "    nlp = es_core_news_sm.load()\n",
    "    doc = nlp(lower_text)\n",
    "    tokens=[]\n",
    "    # revision de signos de puntuacion y en caso de que no sea se agrega\n",
    "    for token in doc:\n",
    "        if token.is_punct==False:\n",
    "            tokens.append(token.text)\n",
    "\n",
    "    clean_text = \" \".join(tokens)\n",
    "\n",
    "    #Stopwords\n",
    "    new_tokens = word_tokenize(clean_text)\n",
    "    clean_tokens = [w for w in new_tokens if not w in stop_words]\n",
    "    final_text = \" \".join(clean_tokens)\n",
    "    \n",
    "    # Guarda\n",
    "    new_path = path[:53] + '-clean' + path[53:]\n",
    "    with open(new_path, 'w') as f:\n",
    "        f.write(f'{title}\\n{final_text}')\n",
    "    \n",
    "    # returns\n",
    "    return (int(path[54:-4]), clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab126ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "def vect(df, id, cleantokens):\n",
    "    current = list(df.columns)\n",
    "    c = set(cleantokens)\n",
    "    zvect = [0] * df.shape[0]\n",
    "    for p in c:\n",
    "        if p not in current:\n",
    "            df[p] = zvect\n",
    "            current.append(p)\n",
    "    d = dict()\n",
    "    for it in current:\n",
    "        if it in c:\n",
    "            sum = cleantokens.count(it)\n",
    "            d[it] = sum/len(cleantokens)\n",
    "        else:\n",
    "            d[it] = 0\n",
    "    new_record = pd.DataFrame([d])\n",
    "    df = pd.concat([df, new_record], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc19e30",
   "metadata": {},
   "source": [
    "# Web Scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f3f249",
   "metadata": {},
   "source": [
    "## Crear el proyecto de Scrappy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "936782aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: scrapy.cfg already exists in C:\\Users\\Usuario\\Documents\\Github\\LibreriaUNAL\\Trabajo 2\\GoodReadsScraper\n",
      "c:\\Users\\Usuario\\Documents\\Github\\LibreriaUNAL\\Trabajo 2\\GoodReadsScraper\\GoodReadsScraper\\spiders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "!scrapy startproject GoodReadsScraper\n",
    "%cd GoodReadsScraper/GoodReadsScraper/spiders/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e222ef3",
   "metadata": {},
   "source": [
    "## Crear un nuevo Spyder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2db7962f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Documents\\Github\\LibreriaUNAL\\Trabajo 2\\GoodReadsScraper\\GoodReadsScraper\\spiders\\GoodReadsSpider.py already exists\n"
     ]
    }
   ],
   "source": [
    "!scrapy genspider GoodReadsSpider https://www.goodreads.com/shelf/show/fiction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28553641",
   "metadata": {},
   "source": [
    "## Ejecutar el Spyder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cacb4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 10:51:11 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: GoodReadsScraper)\n",
      "2023-10-31 10:51:11 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.12.0 (tags/v3.12.0:0fb18b0, Oct  2 2023, 13:03:39) [MSC v.1935 64 bit (AMD64)], pyOpenSSL 23.3.0 (OpenSSL 3.1.4 24 Oct 2023), cryptography 41.0.5, Platform Windows-10-10.0.19045-SP0\n",
      "2023-10-31 10:51:11 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2023-10-31 10:51:11 [asyncio] DEBUG: Using selector: SelectSelector\n",
      "2023-10-31 10:51:11 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\n",
      "2023-10-31 10:51:11 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop\n",
      "2023-10-31 10:51:11 [scrapy.extensions.telnet] INFO: Telnet Password: 034972bf29d08478\n",
      "2023-10-31 10:51:11 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2023-10-31 10:51:11 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'BOT_NAME': 'GoodReadsScraper',\n",
      " 'FEED_EXPORT_ENCODING': 'utf-8',\n",
      " 'NEWSPIDER_MODULE': 'GoodReadsScraper.spiders',\n",
      " 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\n",
      " 'ROBOTSTXT_OBEY': True,\n",
      " 'SPIDER_LOADER_WARN_ONLY': True,\n",
      " 'SPIDER_MODULES': ['GoodReadsScraper.spiders'],\n",
      " 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}\n",
      "2023-10-31 10:51:12 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2023-10-31 10:51:12 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2023-10-31 10:51:12 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2023-10-31 10:51:12 [scrapy.core.engine] INFO: Spider opened\n",
      "2023-10-31 10:51:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2023-10-31 10:51:12 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2023-10-31 10:51:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.goodreads.com/robots.txt> (referer: None)\n",
      "2023-10-31 10:51:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.goodreads.com/shelf/show/fiction> (referer: None)\n",
      "2023-10-31 10:51:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.goodreads.com/book/show/61439040-1984> (referer: https://www.goodreads.com/shelf/show/fiction)\n",
      "2023-10-31 10:51:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.goodreads.com/book/show/170448.Animal_Farm> (referer: https://www.goodreads.com/shelf/show/fiction)\n",
      "2023-10-31 10:51:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.goodreads.com/book/show/2767052-the-hunger-games> (referer: https://www.goodreads.com/shelf/show/fiction)\n",
      "2023-10-31 10:51:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.goodreads.com/book/show/38447.The_Handmaid_s_Tale> (referer: https://www.goodreads.com/shelf/show/fiction)\n",
      "2023-10-31 10:51:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.goodreads.com/book/show/4671.The_Great_Gatsby> (referer: https://www.goodreads.com/shelf/show/fiction)\n",
      "2023-10-31 10:51:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.goodreads.com/book/show/2657.To_Kill_a_Mockingbird> (referer: https://www.goodreads.com/shelf/show/fiction)\n",
      "2023-10-31 10:51:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.goodreads.com/book/show/5107.The_Catcher_in_the_Rye> (referer: https://www.goodreads.com/shelf/show/fiction)\n",
      "2023-10-31 10:51:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.goodreads.com/book/show/72193.Harry_Potter_and_the_Philosopher_s_Stone> (referer: https://www.goodreads.com/shelf/show/fiction)\n",
      "2023-10-31 10:51:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.goodreads.com/book/show/968.The_Da_Vinci_Code> (referer: https://www.goodreads.com/shelf/show/fiction)\n",
      "2023-10-31 10:51:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.goodreads.com/book/show/18144590-the-alchemist> (referer: https://www.goodreads.com/shelf/show/fiction)\n",
      "2023-10-31 10:51:16 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2023-10-31 10:51:16 [scrapy.extensions.feedexport] INFO: Stored json feed (0 items) in: ../../ejercicio0.json\n",
      "2023-10-31 10:51:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 4934,\n",
      " 'downloader/request_count': 12,\n",
      " 'downloader/request_method_count/GET': 12,\n",
      " 'downloader/response_bytes': 7745291,\n",
      " 'downloader/response_count': 12,\n",
      " 'downloader/response_status_count/200': 12,\n",
      " 'elapsed_time_seconds': 4.923857,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2023, 10, 31, 15, 51, 16, 955973, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 283953,\n",
      " 'httpcompression/response_count': 2,\n",
      " 'log_count/DEBUG': 15,\n",
      " 'log_count/INFO': 11,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 12,\n",
      " 'robotstxt/request_count': 1,\n",
      " 'robotstxt/response_count': 1,\n",
      " 'robotstxt/response_status_count/200': 1,\n",
      " 'scheduler/dequeued': 11,\n",
      " 'scheduler/dequeued/memory': 11,\n",
      " 'scheduler/enqueued': 11,\n",
      " 'scheduler/enqueued/memory': 11,\n",
      " 'start_time': datetime.datetime(2023, 10, 31, 15, 51, 12, 32116, tzinfo=datetime.timezone.utc)}\n",
      "2023-10-31 10:51:16 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "!scrapy runspider GoodReadsSpider.py -O ../../ejercicio0.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5dac09",
   "metadata": {},
   "source": [
    "# Pre-procesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09c117b",
   "metadata": {},
   "source": [
    "## Leer archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e8108b30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To Kill a Mockingbird\n",
      "The unforgettable novel of a childhood in a sleepy Southern town and the crisis of conscience that rocked it. \"To Kill A Mockingbird\" became both an instant bestseller and a critical success when it was first published in 1960. It went on to win the Pulitzer Prize in 1961 and was later made into an Academy Award-winning film, also a classic.\n"
     ]
    }
   ],
   "source": [
    "path = 'C:\\\\Users\\\\dgbla\\\\GitHub\\\\LibreriaUNAL\\\\Trabajo 2\\\\archivos\\\\4.txt'\n",
    "with open(path, 'r') as f:\n",
    "    file = f.readlines()\n",
    "title = file[0][:-1]\n",
    "synopsis = \" \".join(file[1::])\n",
    "print(title)\n",
    "print(synopsis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfd126b",
   "metadata": {},
   "source": [
    "## Poner todo en minuscula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c2095d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the unforgettable novel of a childhood in a sleepy southern town and the crisis of conscience that rocked it. \"to kill a mockingbird\" became both an instant bestseller and a critical success when it was first published in 1960. it went on to win the pulitzer prize in 1961 and was later made into an academy award-winning film, also a classic.\n"
     ]
    }
   ],
   "source": [
    "lower_text = synopsis.lower()\n",
    "print(lower_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97e0018",
   "metadata": {},
   "source": [
    "## Eliminar signos de Puntuacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9e91096b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the unforgettable novel of a childhood in a sleepy southern town and the crisis of conscience that rocked it to kill a mockingbird became both an instant bestseller and a critical success when it was first published in 1960 it went on to win the pulitzer prize in 1961 and was later made into an academy award-winning film also a classic\n"
     ]
    }
   ],
   "source": [
    "nlp = es_core_news_sm.load()\n",
    "doc = nlp(lower_text)\n",
    "tokens=[]\n",
    "# revision de signos de puntuacion y en caso de que no sea se agrega\n",
    "for token in doc:\n",
    "  if token.is_punct==False:\n",
    "    tokens.append(token.text)\n",
    "\n",
    "clean_text = \" \".join(tokens)\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40da9fec",
   "metadata": {},
   "source": [
    "## Eliminar las Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "62c9dd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add(\"\\\"\")\n",
    "stop_words.add(\"'\")\n",
    "stop_words.add(\"’\")\n",
    "stop_words.add(\"”\")\n",
    "stop_words.add(\"!\")\n",
    "stop_words.add(\"“\")\n",
    "stop_words.add(\"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "752502dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'unforgettable', 'novel', 'of', 'a', 'childhood', 'in', 'a', 'sleepy', 'southern', 'town', 'and', 'the', 'crisis', 'of', 'conscience', 'that', 'rocked', 'it', 'to', 'kill', 'a', 'mockingbird', 'became', 'both', 'an', 'instant', 'bestseller', 'and', 'a', 'critical', 'success', 'when', 'it', 'was', 'first', 'published', 'in', '1960', 'it', 'went', 'on', 'to', 'win', 'the', 'pulitzer', 'prize', 'in', '1961', 'and', 'was', 'later', 'made', 'into', 'an', 'academy', 'award-winning', 'film', 'also', 'a', 'classic']\n",
      "['unforgettable', 'novel', 'childhood', 'sleepy', 'southern', 'town', 'crisis', 'conscience', 'rocked', 'kill', 'mockingbird', 'became', 'instant', 'bestseller', 'critical', 'success', 'first', 'published', '1960', 'went', 'win', 'pulitzer', 'prize', '1961', 'later', 'made', 'academy', 'award-winning', 'film', 'also', 'classic']\n",
      "unforgettable novel childhood sleepy southern town crisis conscience rocked kill mockingbird became instant bestseller critical success first published 1960 went win pulitzer prize 1961 later made academy award-winning film also classic\n"
     ]
    }
   ],
   "source": [
    "new_tokens = word_tokenize(clean_text)\n",
    "print(new_tokens)\n",
    "clean_tokens = [w for w in new_tokens if not w in stop_words]\n",
    "print(clean_tokens)\n",
    "final_text = \" \".join(clean_tokens)\n",
    "print(final_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bc3e14",
   "metadata": {},
   "source": [
    "## Guardar archivo modificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2a04df52",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\dgbla\\\\GitHub\\\\LibreriaUNAL\\\\Trabajo 2\\\\archivos-clean\\\\3.txt'\n",
    "with open(path, 'w') as f:\n",
    "    f.write(f'{title}\\n{final_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a5ce8e",
   "metadata": {},
   "source": [
    "## Agregar nuevo documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f451c1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Ruta de la carpeta que deseas contar\n",
    "carpeta = 'C:\\\\Users\\\\Usuario\\\\Documents\\\\Github\\\\LibreriaUNAL\\\\Trabajo 2\\\\archivos\\\\'\n",
    "\n",
    "# Lista todos los archivos en la carpeta\n",
    "archivos_en_carpeta = os.listdir(carpeta)\n",
    "\n",
    "# Filtra la lista para contar solo los archivos (no directorios)\n",
    "archivos = [archivo for archivo in archivos_en_carpeta if os.path.isfile(os.path.join(carpeta, archivo))]\n",
    "\n",
    "# Cuenta los archivos\n",
    "cantidad_de_archivos = len(archivos)\n",
    "\n",
    "def createDocument(title, synopsis):\n",
    "    \n",
    "    # Ruta de la carpeta que deseas contar\n",
    "    carpeta = 'C:\\\\Users\\\\Usuario\\\\Documents\\\\Github\\\\LibreriaUNAL\\\\Trabajo 2\\\\archivos\\\\' #Pc trabajo Jairo\n",
    "    \n",
    "    # Lista todos los archivos en la carpeta\n",
    "    archivos_en_carpeta = os.listdir(carpeta)\n",
    "\n",
    "    # Filtra la lista para contar solo los archivos (no directorios)\n",
    "    archivos = [archivo for archivo in archivos_en_carpeta if os.path.isfile(os.path.join(carpeta, archivo))]\n",
    "\n",
    "    # Cuenta los archivos\n",
    "    cantidad_de_archivos = len(archivos) + 1\n",
    "    \n",
    "    path = 'C:\\\\Users\\\\Usuario\\\\Documents\\\\Github\\\\LibreriaUNAL\\\\Trabajo 2\\\\archivos\\\\'+ str(cantidad_de_archivos) + '.txt' #Pc trabajo Jairo\n",
    "        \n",
    "    with open(path, 'w') as f:\n",
    "        f.write(f'{title}\\n{synopsis}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b91728fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sinopsis agregada a la DB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "title = 'Ingrese el titulo'\n",
    "sinopsis = 'Ingrese la sinopsis'\n",
    "\n",
    "\n",
    "# Ruta de la carpeta que contiene los archivos .txt\n",
    "folder = 'C:\\\\Users\\\\Usuario\\\\Documents\\\\Github\\\\LibreriaUNAL\\\\Trabajo 2\\\\archivos\\\\' #Pc del trabajo Jairo\n",
    "\n",
    "repetedFlag = False\n",
    "\n",
    "# Recorrer los archivos en la carpeta\n",
    "for archivo in os.listdir(folder):\n",
    "    if archivo.endswith('.txt'):\n",
    "        ruta_archivo = os.path.join(folder, archivo)\n",
    "        with open(ruta_archivo, 'r') as f:\n",
    "            lineas = f.readlines()\n",
    "            if lineas:\n",
    "                titulo = lineas[0].strip()  # Guarda la primera línea sin espacios en blanco\n",
    "                if titulo == title: \n",
    "                    resto = ''.join(lineas[1:])  # Concatena el resto del contenido\n",
    "                    if resto == sinopsis:\n",
    "                        repetedFlag = True\n",
    "if not repetedFlag:\n",
    "    createDocument(title, sinopsis)\n",
    "    print('Sinopsis agregada a la DB')\n",
    "else:\n",
    "    print('La sinopsis ya existe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf569116",
   "metadata": {},
   "source": [
    "# Vectorizacion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ad141a",
   "metadata": {},
   "source": [
    "## Dataframe of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b274030a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ddb3eb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "current = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "483a6a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = set(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7acb801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zvect = [0] * df.shape[0]\n",
    "for p in c:\n",
    "    if p not in current:\n",
    "        df[p] = zvect\n",
    "        current.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2edc3a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict()\n",
    "for it in current:\n",
    "    if it in c:\n",
    "        sum = clean_tokens.count(it)\n",
    "        d[it] = sum/len(clean_tokens)\n",
    "    else:\n",
    "        d[it] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d7187742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>capitol</th>\n",
       "      <th>ruins</th>\n",
       "      <th>north</th>\n",
       "      <th>panem</th>\n",
       "      <th>annual</th>\n",
       "      <th>keeps</th>\n",
       "      <th>tv</th>\n",
       "      <th>live</th>\n",
       "      <th>one</th>\n",
       "      <th>hunger</th>\n",
       "      <th>...</th>\n",
       "      <th>classic</th>\n",
       "      <th>kill</th>\n",
       "      <th>rocked</th>\n",
       "      <th>childhood</th>\n",
       "      <th>went</th>\n",
       "      <th>mockingbird</th>\n",
       "      <th>success</th>\n",
       "      <th>later</th>\n",
       "      <th>film</th>\n",
       "      <th>bestseller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    capitol     ruins     north     panem    annual     keeps        tv  \\\n",
       "0  0.054054  0.027027  0.027027  0.027027  0.027027  0.027027  0.027027   \n",
       "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "       live       one    hunger  ...   classic      kill    rocked  childhood  \\\n",
       "0  0.027027  0.054054  0.027027  ...  0.000000  0.000000  0.000000   0.000000   \n",
       "1       NaN       NaN       NaN  ...  0.032258  0.032258  0.032258   0.032258   \n",
       "\n",
       "       went  mockingbird   success     later      film  bestseller  \n",
       "0  0.000000     0.000000  0.000000  0.000000  0.000000    0.000000  \n",
       "1  0.032258     0.032258  0.032258  0.032258  0.032258    0.032258  \n",
       "\n",
       "[2 rows x 64 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c098858c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>capitol</th>\n",
       "      <th>ruins</th>\n",
       "      <th>north</th>\n",
       "      <th>panem</th>\n",
       "      <th>annual</th>\n",
       "      <th>keeps</th>\n",
       "      <th>tv</th>\n",
       "      <th>live</th>\n",
       "      <th>one</th>\n",
       "      <th>hunger</th>\n",
       "      <th>...</th>\n",
       "      <th>classic</th>\n",
       "      <th>kill</th>\n",
       "      <th>rocked</th>\n",
       "      <th>childhood</th>\n",
       "      <th>went</th>\n",
       "      <th>mockingbird</th>\n",
       "      <th>success</th>\n",
       "      <th>later</th>\n",
       "      <th>film</th>\n",
       "      <th>bestseller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    capitol     ruins     north     panem    annual     keeps        tv  \\\n",
       "0  0.054054  0.027027  0.027027  0.027027  0.027027  0.027027  0.027027   \n",
       "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       live       one    hunger  ...   classic      kill    rocked  childhood  \\\n",
       "0  0.027027  0.054054  0.027027  ...  0.000000  0.000000  0.000000   0.000000   \n",
       "1       NaN       NaN       NaN  ...  0.032258  0.032258  0.032258   0.032258   \n",
       "2  0.000000  0.000000  0.000000  ...  0.032258  0.032258  0.032258   0.032258   \n",
       "\n",
       "       went  mockingbird   success     later      film  bestseller  \n",
       "0  0.000000     0.000000  0.000000  0.000000  0.000000    0.000000  \n",
       "1  0.032258     0.032258  0.032258  0.032258  0.032258    0.032258  \n",
       "2  0.032258     0.032258  0.032258  0.032258  0.032258    0.032258  \n",
       "\n",
       "[3 rows x 64 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_record = pd.DataFrame([d])\n",
    "df = pd.concat([df, new_record], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b589fd5",
   "metadata": {},
   "source": [
    "# Base de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b1b5e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n",
      "C:\\Users\\dgbla\\AppData\\Local\\Temp\\ipykernel_59292\\1710188919.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[p] = zvect\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timely</th>\n",
       "      <th>thirty-five</th>\n",
       "      <th>city-wide</th>\n",
       "      <th>hailed</th>\n",
       "      <th>solid</th>\n",
       "      <th>orwell</th>\n",
       "      <th>slums</th>\n",
       "      <th>called</th>\n",
       "      <th>science</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>...</th>\n",
       "      <th>christianity</th>\n",
       "      <th>unravel</th>\n",
       "      <th>reveal</th>\n",
       "      <th>potentially</th>\n",
       "      <th>secret</th>\n",
       "      <th>truth</th>\n",
       "      <th>works</th>\n",
       "      <th>da</th>\n",
       "      <th>evidence</th>\n",
       "      <th>follows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     timely  thirty-five  city-wide    hailed     solid    orwell     slums  \\\n",
       "0  0.020833     0.020833   0.020833  0.020833  0.020833  0.020833  0.020833   \n",
       "1  0.000000     0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000     0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000     0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000     0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5  0.000000     0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "6  0.000000     0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7  0.000000     0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "8  0.000000     0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "9  0.000000     0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "     called   science  abandoned  ...  christianity   unravel    reveal  \\\n",
       "0  0.020833  0.020833   0.020833  ...      0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000   0.000000  ...      0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000   0.000000  ...      0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000   0.000000  ...      0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000   0.000000  ...      0.000000  0.000000  0.000000   \n",
       "5  0.000000  0.000000   0.000000  ...      0.000000  0.000000  0.000000   \n",
       "6  0.000000  0.000000   0.000000  ...      0.000000  0.000000  0.000000   \n",
       "7  0.000000  0.000000   0.000000  ...      0.000000  0.000000  0.000000   \n",
       "8  0.000000  0.000000   0.000000  ...      0.000000  0.000000  0.000000   \n",
       "9  0.000000  0.000000   0.000000  ...      0.030303  0.030303  0.030303   \n",
       "\n",
       "   potentially    secret     truth     works        da  evidence   follows  \n",
       "0     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "5     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "6     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "8     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "9     0.030303  0.030303  0.030303  0.030303  0.030303  0.030303  0.030303  \n",
       "\n",
       "[10 rows x 302 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for p in range(1,11):\n",
    "    path = 'C:\\\\Users\\\\dgbla\\\\GitHub\\\\LibreriaUNAL\\\\Trabajo 2\\\\archivos\\\\' + str(p) + '.txt'\n",
    "    id, clean = preProcess(path)\n",
    "    df = vect(df, id, clean)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3affaa",
   "metadata": {},
   "source": [
    "# Consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f436f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prePro(consulta):\n",
    "    #Minusculas\n",
    "    lower_text = consulta.lower()\n",
    "\n",
    "    #Eliminar signos de puntuación\n",
    "    nlp = es_core_news_sm.load()\n",
    "    doc = nlp(lower_text)\n",
    "    tokens=[]\n",
    "    # revision de signos de puntuacion y en caso de que no sea se agrega\n",
    "    for token in doc:\n",
    "        if token.is_punct==False:\n",
    "            tokens.append(token.text)\n",
    "\n",
    "    clean_text = \" \".join(tokens)\n",
    "\n",
    "    #Stopwords\n",
    "    new_tokens = word_tokenize(clean_text)\n",
    "    clean_tokens = [w for w in new_tokens if not w in stop_words]\n",
    "    \n",
    "    # returns\n",
    "    return clean_tokens\n",
    "\n",
    "def vecto(df, cleantokens):\n",
    "    dfa = df.copy()\n",
    "    current = list(df.columns)\n",
    "    c = set(cleantokens)\n",
    "    zvect = [0] * df.shape[0]\n",
    "    for p in c:\n",
    "        if p not in current:\n",
    "            dfa[p] = zvect\n",
    "            current.append(p)\n",
    "    d = dict()\n",
    "    for it in current:\n",
    "        if it in c:\n",
    "            sum = cleantokens.count(it)\n",
    "            d[it] = sum/len(cleantokens)\n",
    "        else:\n",
    "            d[it] = 0\n",
    "    new_record = pd.DataFrame([d])\n",
    "    return (dfa, new_record)\n",
    "\n",
    "def relevance(vector, document):\n",
    "    producto_punto = np.dot(vector, document)\n",
    "    norma_vector1 = np.linalg.norm(vector)\n",
    "    norma_vector2 = np.linalg.norm(document)\n",
    "    coseno_angulo = producto_punto / (norma_vector1 * norma_vector2)\n",
    "    return coseno_angulo\n",
    "    \n",
    "def consulta(df, consulta):\n",
    "    docs = list()\n",
    "    tokens = prePro(consulta)\n",
    "    dfa, vector = vecto(df, tokens)\n",
    "    vector = vector.to_numpy()\n",
    "    for index, row in dfa.iterrows():\n",
    "        r = relevance(vector, row)\n",
    "        print(r)\n",
    "        if r>0.5:\n",
    "            docs.append(index+1)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1482c0",
   "metadata": {},
   "source": [
    "# Ejemplos consultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d101c5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = consulta(df, \"dreams\")\n",
    "docs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cd9b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fae113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
